# 프로젝트 소개

<div align = "left">
  <img width="700" src="https://github.com/user-attachments/assets/984574f0-565e-4b54-8cca-b869b161389d" />
  <br>
  <p>
    Sol.Pic(Solve Picture)은 수학문제 이미지를 AI를 활용해 풀이과정과 정답을 제공해주는 모바일기반 어플리케이션 입니다.
  </p>
    <a href="https://github.com/SolPict/SolPict-server">클라이언트</a> |
 <a href="https://github.com/SolPict/SolPict-server">서버</a> |
  <a href="https://catnip-puppy-52c.notion.site/0f30ccd74be94f7cb0b00c4bca706361?pvs=4">노션 </a>
</div>

<br>

<a href="https://apps.apple.com/us/app/sol-pic/id6743796011">앱 스토어에서 다운로드 받기</a>

## 구성

<!-- toc -->

  * [분석과정](#%EB%B6%84%EC%84%9D%EA%B3%BC%EC%A0%95)
  * [미리보기](#%EB%AF%B8%EB%A6%AC%EB%B3%B4%EA%B8%B0)
    + [다양한 문제 제공](#%EB%8B%A4%EC%96%91%ED%95%9C-%EB%AC%B8%EC%A0%9C-%EC%A0%9C%EA%B3%B5)
    + [문제풀이 기능](#%EB%AC%B8%EC%A0%9C%ED%92%80%EC%9D%B4-%EA%B8%B0%EB%8A%A5)
    + [리뷰노트 서비스 제공](#%EB%A6%AC%EB%B7%B0%EB%85%B8%ED%8A%B8-%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%A0%9C%EA%B3%B5)
  * [기술 스택](#%EA%B8%B0%EC%88%A0-%EC%8A%A4%ED%83%9D)
    + [프론트엔드](#%ED%94%84%EB%A1%A0%ED%8A%B8%EC%97%94%EB%93%9C)
    + [백엔드](#%EB%B0%B1%EC%97%94%EB%93%9C)
    + [기술선택이유](#%EA%B8%B0%EC%88%A0%EC%84%A0%ED%83%9D%EC%9D%B4%EC%9C%A0)
- [진행 과정](#%EC%A7%84%ED%96%89-%EA%B3%BC%EC%A0%95)
  * [사전 설명](#%EC%82%AC%EC%A0%84-%EC%84%A4%EB%AA%85)
    + [딥러닝 모델이 "사고"해서 수학문제를 풀 수 있을까?](#%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EC%9D%B4-%EC%82%AC%EA%B3%A0%ED%95%B4%EC%84%9C-%EC%88%98%ED%95%99%EB%AC%B8%EC%A0%9C%EB%A5%BC-%ED%92%80-%EC%88%98-%EC%9E%88%EC%9D%84%EA%B9%8C)
    + [기존 수학 문제 풀어주는 AI의 해결과정](#%EA%B8%B0%EC%A1%B4-%EC%88%98%ED%95%99-%EB%AC%B8%EC%A0%9C-%ED%92%80%EC%96%B4%EC%A3%BC%EB%8A%94-ai%EC%9D%98-%ED%95%B4%EA%B2%B0%EA%B3%BC%EC%A0%95)
- [문제, 해결방안](#%EB%AC%B8%EC%A0%9C-%ED%95%B4%EA%B2%B0%EB%B0%A9%EC%95%88)
  * [1. 이미지 인식에서 도전 과제](#1-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%9D%B8%EC%8B%9D%EC%97%90%EC%84%9C-%EB%8F%84%EC%A0%84-%EA%B3%BC%EC%A0%9C)
    + [1-1. 수식으로 인한 이미지 분석(OCR) 과정의 어려움](#1-1-%EC%88%98%EC%8B%9D%EC%9C%BC%EB%A1%9C-%EC%9D%B8%ED%95%9C-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EB%B6%84%EC%84%9Docr-%EA%B3%BC%EC%A0%95%EC%9D%98-%EC%96%B4%EB%A0%A4%EC%9B%80)
  * [2. 딥러닝 모델 적용까지 도전과제](#2-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%EC%A0%81%EC%9A%A9%EA%B9%8C%EC%A7%80-%EB%8F%84%EC%A0%84%EA%B3%BC%EC%A0%9C)
    + [2-1. 모델 새로 만들기 vs. 학습된 모델 활용하기](#2-1-%EB%AA%A8%EB%8D%B8-%EC%83%88%EB%A1%9C-%EB%A7%8C%EB%93%A4%EA%B8%B0-vs-%ED%95%99%EC%8A%B5%EB%90%9C-%EB%AA%A8%EB%8D%B8-%ED%99%9C%EC%9A%A9%ED%95%98%EA%B8%B0)
  * [3. 딥러닝 모델 적용 후 도전과제](#3-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%EC%A0%81%EC%9A%A9-%ED%9B%84-%EB%8F%84%EC%A0%84%EA%B3%BC%EC%A0%9C)
    + [3-1. 수학 문제 해결을 위한 고성능 그래픽 카드(GPU)의 필요성](#3-1-%EC%88%98%ED%95%99-%EB%AC%B8%EC%A0%9C-%ED%95%B4%EA%B2%B0%EC%9D%84-%EC%9C%84%ED%95%9C-%EA%B3%A0%EC%84%B1%EB%8A%A5-%EA%B7%B8%EB%9E%98%ED%94%BD-%EC%B9%B4%EB%93%9Cgpu%EC%9D%98-%ED%95%84%EC%9A%94%EC%84%B1)
    + [3-2. 고성능 GPU 없는 개발 환경에서 개발하기](#3-2-%EA%B3%A0%EC%84%B1%EB%8A%A5-gpu-%EC%97%86%EB%8A%94-%EA%B0%9C%EB%B0%9C-%ED%99%98%EA%B2%BD%EC%97%90%EC%84%9C-%EA%B0%9C%EB%B0%9C%ED%95%98%EA%B8%B0)
  * [4. 딥러닝 모델 정확도 향상 전략](#4-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%EC%A0%95%ED%99%95%EB%8F%84-%ED%96%A5%EC%83%81-%EC%A0%84%EB%9E%B5)
    + [4-1. 딥러닝 모델의 성능을 높이는 이미지 처리 전략](#4-1-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EC%9D%98-%EC%84%B1%EB%8A%A5%EC%9D%84-%EB%86%92%EC%9D%B4%EB%8A%94-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%B2%98%EB%A6%AC-%EC%A0%84%EB%9E%B5)
    + [4-2. 딥러닝 모델의 언어 최적화 전략](#4-2-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8%EC%9D%98-%EC%96%B8%EC%96%B4-%EC%B5%9C%EC%A0%81%ED%99%94-%EC%A0%84%EB%9E%B5)
    + [4-3. 딥러닝 모델 미세학습](#4-3-%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%EB%AF%B8%EC%84%B8%ED%95%99%EC%8A%B5)
  * [5. 긴 분석시간 처리](#5-%EA%B8%B4-%EB%B6%84%EC%84%9D%EC%8B%9C%EA%B0%84-%EC%B2%98%EB%A6%AC)
    + [5-1. 비동기를 활용한 다른 페이지 탐색 기능](#5-1-%EB%B9%84%EB%8F%99%EA%B8%B0%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EB%8B%A4%EB%A5%B8-%ED%8E%98%EC%9D%B4%EC%A7%80-%ED%83%90%EC%83%89-%EA%B8%B0%EB%8A%A5)
- [프로젝트 소감](#%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EC%86%8C%EA%B0%90)

<!-- tocstop -->

## 분석과정

<div align="left">
  <img width="700" alt="image-1" src="https://github.com/user-attachments/assets/7daf2431-ab11-4321-967f-ce1086d92cf6">
</div>

## 미리보기

### 다양한 문제 제공

<details>
<summary>펼치기</summary>
<div markdown="1">
<div align="left">
  <img src="https://github.com/user-attachments/assets/65386a10-6372-42cd-9898-4dcc187182af"  width="200" height="400" />
</div>
</div>
</details>

### 문제풀이 기능

<details>
<summary>펼치기</summary>
<div markdown="2">
<div align="left">
  <img src="https://github.com/user-attachments/assets/bac8d9ca-2778-472a-9762-30069dc7d327"  width="200" height="400" />
  <img src="https://github.com/user-attachments/assets/86cb313c-b7a3-4a3a-8cdc-c979ea2cf27b"  width="200" height="400" />
</div>
</div>
</details>

### 리뷰노트 서비스 제공

<details>
<summary>펼치기</summary>
<div markdown="3">
<div align="left">
  <img src="https://github.com/user-attachments/assets/92274187-b471-4a08-add5-163542f834b7"  width="200" height="400" />
  <img src="https://github.com/user-attachments/assets/c1fe6738-28f7-4982-8238-242166891660"  width="200" height="400" />
  <img src="https://github.com/user-attachments/assets/b56e6e2f-93ba-4b6d-bb96-3a5dc28f2dab"  width="200" height="400" />
</div>
</details>

</div>

## 기술 스택

### 프론트엔드

<div align="left">
<a href="https://github.com/msdio/stackticon"><img src="https://firebasestorage.googleapis.com/v0/b/stackticon-81399.appspot.com/o/images%2F1729064190666?alt=media&token=ee57095c-a352-4385-ad04-b6b2fe07ae55" alt="프론트엔드" /></a>
</div>

### 백엔드

<div align="left">
<a href="https://github.com/msdio/stackticon"><img src="https://firebasestorage.googleapis.com/v0/b/stackticon-81399.appspot.com/o/images%2F1729064135249?alt=media&token=0a739831-764a-4485-a2b0-3bff371a377f" alt="백엔드" /></a>
</div>

### 기술선택이유

- **모바일 ✓** vs 웹

  - 프로젝트의 메인기능인 이미지를 찍어서 문제를 해결하는 과정을 거치므로 유저입장에서 쉽게 이미지를 찍을 수 있는 **모바일** 기술을 선택하였습니다.
  - 모바일일 경우 좀 더 유연한 환경에서 서비스를 제공받을 수 있기 때문에 사용자 경험을 극대화하기 위해 **모바일** 기술을 선택하였습니다.

- **Expo ✓** vs Cli

  - 짧은 프로젝트 기한 동안 여러 가지를 구현해야 하는 입장으로써 다양한 API와 Expo Go라는 앱을 제공해 주어 개발을 용이하게 도와주기 때문에 **Expo**를 선택하였습니다.
  - 모바일 플랫폼 환경에서 처음으로 개발해 보기 때문에 초기세팅과 빌드 및 배포 그리고 학습적인 측면에서 좀 더 간편하기 때문에
    **Expo**를 선택하였습니다.

- **Python ✓** vs Javascript

  - 프로젝트에서 딥러닝 모델을 사용해야 해야 해서 pytorch 또는 TensorFlow가 꼭 필요한 상황이었기 때문에 **Python**언어를 선택하였습니다.
  - 그 외에도 수식 관련 다룰 수 있는 SymPy, 이미지 처리(OCR) 관련해서도 OpenCV, EasyOCR 등 데이터를 조작하고 다룰 수 있게 도와주는 라이브러리들이 많았기 때문에 **Python**언어를 선택하였습니다.

- **S3 ✓**
  - 기존 데이터베이스(MongoDB)가 있지만 프로젝트 특성상 이미지라는 용량이 큰 파일을 다루기 때문에 대용량의 데이터를 다루기 용이한 **S3**을 선택하였습니다.
  - 클라이언트 측에서도 쉽게 접근할 수 있는 기능을 제공해 주기 때문에 서버의 부담을 줄일 수 있고 요청 또한 서버와 병렬적으로 보내서 작업할 수 있기 때문에 **S3**을 선택하였습니다.

# 진행 과정

총 프로젝트 기간: 9월 2일 ~ 10월 2일

| **주차**  | **계획**                                                                                                                                                                                             |
| --------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **1주차** | - 아이디어 선정<br> - 선정된 아이디어 기술 스택 결정 및 검증                                                                                                                                         |
| **2주차** | - Expo 이용한 새로운 플랫폼(모바일) 정적페이지 구현<br> - 이미지 분석(OCR) 기술 구현 가능 여부 판단 -> API 사용으로 결론<br> - 딥러닝 모델 구현 가능 여부 판단 -> 학습된 딥러닝 모델 가져오기로 결론 |
| **3주차** | - 프로젝트에 적합한 이미지 분석(OCR) API 탐색 및 적용<br> - 프로젝트에 적합한 딥러닝 모델 탐색 및 적용                                                                                               |
| **4주차** | - 새로운 환경(FastAPI) 서버 CRUD 구현<br> - 클라이언트측 UI, UX 구현<br> - GPU 부재로 인한 집에서 서버 연결<br> - 상호연결에 의한 에러 처리                                                          |

## 사전 설명

### 딥러닝 모델이 "사고"해서 수학문제를 풀 수 있을까?

해당 질문의 답변은 "사고"해서 풀 수 없습니다.

"사고"의 사전적 의미로는 "어떤 것에 대하여 깊이 있게 생각한다."라는 뜻이 있습니다. 그럼 여기서 "생각한다"의 사전적 의미를 한 번 더 살펴보면 "결론을 얻으려고 헤아리고 판단하고 인식하는 관념의 과정"이라는 뜻을 찾을 수 있습니다.

AI와 사람을 비교했을 때, 사람의 경우 직관적이고 창의적인 과정을 통해 수학 문제를 해결합니다. 반면 AI는 대규모 데이터를 기반으로 규칙을 찾아내어 결과를 추론하고 예측하는 방식으로 문제에 접근하므로, “사고”를 한다고 볼 수 없습니다.

때문에 AI경우 수 많은 데이터를 기반으로 정답에 근접한 값을 단순히 "찾는다" 라는 표현이 더 가깝습니다.

그러면 어떻게 수학문제를 풀어야 할까요?

### 기존 수학 문제 풀어주는 AI의 해결과정

대부분의 서비스에서 AI가 수학문제를 풀 수 있는 것의 대한 해답은 **문제 전체**를 구조화된 코드 형태로 바꾸는 것에 있습니다.

구조화된 형태로 변환된 수학 문제는 딥러닝 AI에 의해 큰 문제 유형(대수학, 기하학, 통계학 등등)으로 먼저 분류됩니다. 그 후, 세부적으로(이차 방정식, 미적분, 확률과 통계 등등) 다시 분류되어 각 유형에 맞는 풀이 과정을 거칩니다. 문제 해결 과정과 정답은 기록되어, 마지막으로 자연어 생성(NLG) 과정을 통해 사용자에게 풀이 과정과 함께 결과가 제공됩니다.

<div align="left">
  <img width="700" alt="image" src="https://github.com/user-attachments/assets/b72259c8-492b-4060-a10c-0e075dc695c3">
</div>
<br>
<br>

# 문제, 해결방안

## 1. 이미지 인식에서 도전 과제

### 1-1. 수식으로 인한 이미지 분석(OCR) 과정의 어려움

이미지 분석에서 정확도를 Confident로 나타낼 수 있는데 1에 가까울 수록 높은 정확도를 나타냅니다.

기존에 사용하려던 이미지 분석(OCR) 기술은 수식이 아닌 텍스트에 대해서는 비교적 정확하게 분석하는 것을 확인할 수 있고 텍스트 분석 결과의 신뢰도(Confident)가 1에 가까웠습니다. 하지만, 수식에 대한 분석은 정확도가 떨어지며, 신뢰도(Confident)가 0에 가까운 결과를 보여주었습니다.

|                                                     기존 이미지                                                     |                                                      분석 결과                                                      |
| :-----------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------: |
| <img width="300" alt="image" src="https://github.com/user-attachments/assets/17a8f385-742f-43b2-bb9c-449251cdf936"> | <img width="200" alt="image" src="https://github.com/user-attachments/assets/71410eda-12a2-4720-be1e-dfa8630b9e7e"> |

<br>

그렇게 수식을 인식시킬 방법을 고민하다가 두 가지 방법을 시도했습니다.

<INS>첫 번째 방법</INS>은 OpenCV를 사용하여 수식 영역과 텍스트 영역을 분리한 후, 각각 따로 분석하는 방식이었습니다.
그러나 이 방법에서는 영역 분리가 제대로 이루어지지 않았고, 기대했던 성과를 얻기 위해선 openCV에 대해 깊게 공부할 시간이 필요하다는 것을 깨달았습니다.
<br>

|                                                     기존 이미지                                                     |                                                      분석 결과                                                      |
| :-----------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------: |
| <img width="300" alt="image" src="https://github.com/user-attachments/assets/cc6ff7a4-db3d-4f0a-b95f-8ca7a5df4228"> | <img width="300" alt="image" src="https://github.com/user-attachments/assets/2c86c052-0b2f-4a76-9d73-814abf11161b"> |

<INS>두 번째 방법</INS>은 여러 수식 전용 외부 API 서비스를 비교한 후, 가장 정확하게 수식을 분석해 주는 API를 선택하는 것이었습니다.
이 방법을 통해, 수식과 텍스트 영역을 별도로 처리하는 대신, 수식 인식에 특화된 API를 사용하여 보다 정확한 결과를 얻을 수 있었습니다. 그 결과, 수식 분석이 성공적으로 완료되었고, 이전 방식에서 겪었던 문제들을 해결할 수 있었습니다.

|                                                     기존 이미지                                                     |                                                      분석 결과                                                      |
| :-----------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------: |
| <img width="300" alt="image" src="https://github.com/user-attachments/assets/495a3b71-a2b3-40f3-98bf-1021310114dc"> | <img width="300" alt="image" src="https://github.com/user-attachments/assets/5f46dace-1f49-4430-a558-ad5c98d5a14f"> |

## 2. 딥러닝 모델 적용까지 도전과제

### 2-1. 모델 새로 만들기 vs. 학습된 모델 활용하기

제가 선택한 방법은 기존에 학습된 모델을 활용하는 것이었습니다. 이를 선택한 이유는 두 가지입니다.

<INS>첫째,</INS> 딥러닝 모델을 만들기 위한 학습시간이 부족했습니다.

딥러닝 모델을 만들기 위해서는 신경망의 구조, 역전파 알고리즘, 손실 함수의 작동 원리 등 딥러닝의 핵심 개념들을 깊이 이해해야 합니다. 또한, 모델을 만든 후에는 최적화 작업도 필요하며, 이는 높은 수준의 지식과 경험이 요구됩니다. 이 과정에는 많은 시간이 소요되기 때문에, 시간을 보다 효율적으로 관리하기 위해 기존에 학습된 모델을 활용하는 방법을 선택했습니다.

<INS>둘째,</INS> 학습에 필요한 데이터 양이 충분하지 않았습니다.

딥러닝 모델이 좋은 성능을 발휘하려면 많은 양의 학습 데이터가 필요합니다. 특히, 수학 문제 풀이와 관련된 모델의 경우 문제 유형에 따른 다양한 데이터를 확보해야 하는데, 이는 수학적 개념, 문제의 난이도, 문제 유형에 따라 달라질 수 있지만, 일반적으로 모델을 제대로 학습시키려면 최소 10,000개 이상의 많은 양의 데이터(문제, 풀이, 정답)가 필요합니다. 때문에 프로젝트 기한 동안 충분한 데이터를 확보하기 어렵다고 판단해서 학습된 모델을 활용하는 방법을 선택했습니다.

<div align="left">
  <img width="700" alt="image" src="https://github.com/user-attachments/assets/3ab06a1a-d6b6-49b0-aedd-ca46685fcdaa">
</div>
<br>

이러한 이유로 이미 학습된 모델을 가져와 제가 원하는 방향으로 추가 학습시키는 방식을 선택했습니다. 제가 사용한 모델은 단순한 수학 문제를 입력받아 풀이 과정과 답을 제공하는 AI 딥러닝 모델이었습니다.

## 3. 딥러닝 모델 적용 후 도전과제

### 3-1. 수학 문제 해결을 위한 고성능 그래픽 카드(GPU)의 필요성

딥러닝 모델을 사용하는데 가장 큰 어려움은 **그래픽카드(GPU)의 부재**였습니다.

그래픽카드가 필요한 이유는 2가지가 존재하는데

<INS>첫 번째 이유는 </INS> 대규모 딥러닝 모델(LLM)이 연산을 수행하는 데 많은 시간이 걸리기 때문입니다.
연산을 수행하는데 복잡하고 많은 행렬 계산이 필요합니다. 연산을 CPU로 처리할 경우 상당한 시간이 소요되어 성능 저하를 초래할 수 있는 반면, GPU는 병렬 작업에 특화되어 있어 동시에 많은 계산을 수행할 수 있어 연산 시간을 획기적으로 단축할 수 있습니다. 그렇기 때문에 수학 문제를 해결할때 복잡한 수식과 행렬 계산을 GPU를 사용하면 훨씬 더 빠르게 처리할 수 있습니다.

<INS>두 번째 이유</INS>는 대규모 딥러닝 모델(LLM)을 학습하고 훈련하는 과정에서도 많은 시간이 필요합니다.
대규모 모델을 학습하기 위해선 최소 몇 백만에서 많게는 수 억개의 매개변수를 조정해야 합니다.따라서 시간을 효율적으로 단축하기 위해 병렬적으로 수행해야 하며, GPU의 병렬 처리 능력을 활용하여 훈련 시간을 크게 단축할 수 있습니다.

따라서, 대규모 딥러닝 모델에서 연산과 훈련 과정에서 요구되는 많은 시간을 효율적으로 단축할 수 있도록 도와줍니다.

### 3-2. 고성능 GPU 없는 개발 환경에서 개발하기

딥러닝 모델을 사용하기 위해서는 고성능 GPU가 반드시 필요했지만 프로젝트를 진행했던 개발 환경에서는 GPU가 부재인 상황이였습니다. 그래서 이를 해결하기 위해 <INS>두 가지 방법</INS>을 활용해서 개발을 진행하였습니다.

<INS>첫 번째 방법으로는</INS>, 클라우드 기반 개발 환경인 ‘Colab’을 활용했습니다.
Colab은 클라우드 환경에서 고성능 GPU를 제공하므로, 이를 통해 딥러닝 모델을 실행하고, 입력에 따른 출력을 받아와서 사용할 수 있었습니다. 이렇게 클라우드 환경을 이용하면 GPU가 없는 환경에서도 복잡한 모델을 실행한 결과를 받아서 사용할 수 있었습니다.

 <img width="700" alt="image-7" src="https://github.com/user-attachments/assets/3978fcf5-82a9-4fb1-b631-38cc72ac8ccf">

<br>

<INS>두 번째 방법으로는</INS>, 로컬 서버를 외부에서 접근할 수 있게 해주는 도구인 ‘ngrok’을 사용했습니다.
ngrok을 통해 집에 있는 데스크톱 컴퓨터를 서버로 활용할 수 있었습니다. ngrok은 로컬에서 실행 중인 서버를 안전한 터널링을 통해 인터넷에 공개할 수 있게 해주며, 이를 통해 외부 어디서든 로컬 서버에 접근할 수 있습니다. 이렇게 데스크톱의 성능을 활용하여 더 안정적인 환경에서 모델을 실행할 수 있었습니다.

 <img width="700" alt="image" src="https://github.com/user-attachments/assets/8e44e336-7c52-444d-a9a5-0feac95c631b">

 <br>

위의 방법들을 통해 고성능 GPU의 부족 문제를 간접적으로 해결하면서, GPU가 없는 환경에서도 대규모 모델을 사용하면서 개발을 진행할 수 있었습니다.

## 4. 딥러닝 모델 정확도 향상 전략

### 4-1. 딥러닝 모델의 성능을 높이는 이미지 처리 전략

이미지 분석(OCR)을 통한 정확도를 향상하기 위해 저는 <INS>2가지 방법</INS>을 사용하였습니다.

<INS>첫 번째 방법으로</INS>, 비교를 통해서 좀 더 정확도가 높은 API를 사용하였습니다.

기존 OCR 경우 원본 사진이 흐릿하거나 초점이 안맞을 경우 이미지 인식에서 부정확한 경우가 많았습니다. 하지만 새로운 API를 사용하면서 이러한 문제들이 크게 개선되었습니다.

|                                                             변경 전                                                              |                                                             변경 후                                                              |
| :------------------------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------------------------------------------: |
| <img width="300" height="130" alt="image" src="https://github.com/user-attachments/assets/d993e768-e3c3-4022-b6d8-6d63443a1965"> | <img width="300" height="130" alt="image" src="https://github.com/user-attachments/assets/251c775b-1976-45aa-a145-fed607ccb9cd"> |
| <img width="300" height="130" alt="image" src="https://github.com/user-attachments/assets/72adfe4f-9062-48a0-baaf-14e0749277b7"> | <img width="300" height="130" alt="image" src="https://github.com/user-attachments/assets/1f2108e2-3ef5-4d75-a9d8-aa26d0d8181f"> |

원본 사진이 다소 어둡거나 번호 인식에 문제가 있었던 부분이 개선된 것을 확인할 수 있습니다. 더 정확한 분석을 제공하는 API를 통해 이미지 분석의 정확도가 크게 향상되었습니다.

<INS>두 번째 방법으로</INS>, 이미지 자르기 기능과 회전 기능을 추가해 정확도를 더욱 높였습니다.

| 이미지 자르기                                                                                                                    | 이미지 회전                                                                                                           |
| -------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| <img width="200" height="400" alt="image" src="https://github.com/user-attachments/assets/2ad7ee58-b80a-4300-9c33-33b722101fd1"> | <img src="https://github.com/user-attachments/assets/2f44fcaf-004f-4aef-a169-54792b3db69c" width="200" height="400"/> |

위 사진처럼, 이미지 자르기를 통해 불필요한 부분을 제거하여 OCR 처리 시 중요한 부분만 인식할 수 있도록 했습니다. 또한, 기울어진 이미지를 회전 기능으로 보정해, 인식 대상이 똑바로 정렬되도록 하여 인식의 정확도를 더욱 높였습니다. 이러한 전처리 과정은 OCR 엔진이 텍스트를 보다 정확하게 추출할 수 있게 해 주었습니다.

추가로, 더 나은 정확도를 위해 직접 이미지 분석(OCR) 기술을 배우고 활용하는 것도 고려해 볼 수 있습니다. 이 방법은 이미지 전처리와 후처리를 더욱 세밀하게 다룰 수 있게 해 주며, 특정 문제에 맞춤형으로 OCR 성능을 최적화할 수 있는 가능성을 제공합니다. 예를 들어, 텍스트 추출 전 이미지의 노이즈를 제거하거나, 특정 문자 패턴에 맞게 조정하는 등의 작업을 수행할 수 있습니다. 이를 통해 더 정밀한 OCR 처리 결과를 얻을 수 있을 것입니다.

### 4-2. 딥러닝 모델의 언어 최적화 전략

학습된 모델의 사용 언어에 맞춰 입력을 해주는 작업을 통해 정확도를 향상해주는 방법을 사용하였습니다.

| 언어 |                                                               입력                                                               |                                                               결과                                                               |
| :--: | :------------------------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------------------------------------------: |
| 한글 | <img width="300" height="130" alt="image" src="https://github.com/user-attachments/assets/49c29b6d-6d53-40b3-8aed-af4c159aff9b"> | <img width="300" height="130" alt="image" src="https://github.com/user-attachments/assets/43695712-9e9b-430b-b27e-35b40d9c32ea"> |
| 영어 | <img width="300" height="130" alt="image" src="https://github.com/user-attachments/assets/2b86df11-3164-470a-a151-ee3f0c678212"> | <img width="300" height="130" alt="image" src="https://github.com/user-attachments/assets/b165e05f-b064-4b4c-9a3d-a2be8d1629c8"> |

결과를 보면, 한글로 입력했을 때는 "5"라는 오답이 나오는 것을 볼 수 있습니다. 반면, 영어로 입력했을 때는 정상적으로 "0.5 (1/2)"라는 답이 도출되었습니다. 이는 모델이 영어 데이터로 학습된 경우, 영어로 입력할 때 더 정확한 결과를 제공할 수 있다는 것을 보여줍니다.

따라서, 모델에 입력하기 전에 한글 데이터를 영어로 변환하는 전처리 과정을 추가했습니다. 이를 통해, 입력 언어와 모델의 학습 언어를 일치시킴으로써, 결과의 정확도를 향상시킬 수 있었습니다. 이 방법은 특히 모델이 특정 언어에서 학습된 경우에 유용하며, 자연스러운 언어 처리가 중요한 딥러닝 모델에서 효과적으로 사용할 수 있습니다.

이를 통해 입력 데이터와 모델의 학습 데이터 간의 언어적 일관성이 모델 성능에 중요한 영향을 미친다는 점을 확인할 수 있게 해주었습니다.

### 4-3. 딥러닝 모델 미세학습

모델의 정확도를 향상시키기 위한 가장 직접적인 방법은 미세학습(Fine-tuning)입니다.
많은 양의 데이터가 필요했기에 **Hugging Face Hub**에서 제공하는 텍스트 분류용 데이터셋을 활용해 LLM을 기반으로 미세학습을 수행했습니다.

<div align="left">
  <img width="700" src="https://github.com/user-attachments/assets/9bf45bd4-cc67-48fc-8444-ee42c60d2b3e" alt="데이터셋 예시 이미지" />
</div>

학습 프레임워크로는 대형 언어 모델 학습에 특화된 **LLaMA-Factory**를 사용했습니다.
이를 통해 다음과 같은 경량화 및 최적화 기법을 적용할 수 있었습니다.
<br>

1. LoRA (Low-Rank Adaptation): 모델 파라미터 전체가 아닌 일부에만 학습을 적용하여 경량화
2. bitsandbytes 양자화: 모델을 4bit 또는 8bit로 양자화해 GPU 메모리 사용량을 대폭 절감
3. liger-kernel 최적화: 학습 속도 향상 및 자원 효율성 개선

<div align="left">
  <img width="700" src="https://github.com/user-attachments/assets/3e1dac76-1ae7-4c6a-8f9c-6e835c5459a7" alt="LLaMA Factory GUI" />
</div>

최종적으로는 모델과 데이터셋을 옵션에 맞게 설정한 뒤 ‘시작하기’ 버튼을 누르면 설정한 파이프라인을 통해 자동으로 학습이 진행되며 완성된 모델을 바로 받아볼 수 있습니다.

해당 GUI로 학습하는 방법이외에도 CLI 로 진행하는 방법은 별도의 노션에 정리해 두었습니다. ([노션 참조](https://catnip-puppy-52c.notion.site/Huggingface-16a7604d886e8075a4b9f76e9c6747f8?pvs=4))

## 5. 긴 분석시간 처리

### 5-1. 비동기를 활용한 다른 페이지 탐색 기능

사용자가 문제 이미지를 업로드하면, 분석이 진행되는 동안 로딩 화면이 표시됩니다. 이때 사용자는 뒤로 가기 버튼을 눌러 자유롭게 다른 페이지로 이동할 수 있습니다.

| 다른 페이지 이동                                                                                                                 | 완료시 알람 점등                                                                                                      |
| -------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| <img width="200" height="400" alt="image" src="https://github.com/user-attachments/assets/6178fac8-38bd-47b3-8a24-13596c10f90b"> | <img src="https://github.com/user-attachments/assets/cbf94e6f-72ed-4152-b5bc-ad47fd4c7f33" width="200" height="400"/> |

문제 분석이 완료되면, 다음과 같이 두 가지 방식으로 사용자에게 분석 완료를 알립니다:

1. 어떤 페이지에 있든지 상단 알림 아이콘에 빨간 점이 표시되며, 클릭 시 분석 결과 페이지(정답 및 풀이 페이지)로 이동합니다.
2. 사용자가 로딩 화면을 그대로 보고 있을 경우, 하단의 ‘결과보기’ 버튼이 활성화되어 분석 결과 페이지로 바로 진입할 수 있습니다.

이러한 구조는 async/await 기반의 비동기 처리 로직과, 전역 상태를 통해 분석 완료 여부를 공유하는 방식으로 구현되었습니다. 덕분에 분석 도중에도 앱 내 다른 기능을 제약 없이 사용할 수 있으며, 분석 결과가 도출되었을 때는 즉시 확인 가능하도록 UX를 설계했습니다.

<!--
(예정)

4-2. 딥러닝 모델 학습을 통한 정확도 향상

5. 수식으로 인한 문제점

- AI에서 반환된 영어풀이 번역시 문제
- Expo 에서 렌더링시 문제

6. 문제풀이 분석시 요청응답 시간 최적화

- 서브서버 구현
- 다른 페이지로 이동가능
- OCR 미리 요청

7. 이미지 데이터 관련 처리

- 데이터베이스 관리
- 이미지 상태관리
- 메인페이지 이미지들 렌더링 -->

# 프로젝트 소감

기획부터 배포까지 모든 과정을 혼자서 고민하고 선택하며진행함으로써 다양한 것을 느끼고 배울 수 있었습니다.

먼저 기획 단계에서 아이디어를 구체화하고 목업을 만드는 과정에서 다른 사람들과의 협업이 얼마나 중요한지를 실감하게 되었습니다.
또한 어떤 언어, 기술, 플랫폼을 선택할지 등 작은 결정부터큰 방향까지 스스로 판단하며 결과를 직접 체감한 덕분에책임감과 판단력을 기를 수 있었습니다.
구현단계에서는 기능 개발뿐 아니라 UX, 예외 처리, 배포까지직접 고려하며 개발자의 역할 범위와전체적인 코드 흐름을 이해할 수 있는 경험이었습니다.

이러한 경험을 통해 서비스 너머의 코드 흐름을 알 수 있었고스스로 판단하고 이끌어가는 개발자로 한 층 성장할 수 있었습니다.
